<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Sparse Contrastive Principal Component Analysis for Exploring High-Dimensional Biological Data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Philippe Boileau" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="font-size.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Sparse Contrastive Principal Component Analysis for Exploring High-Dimensional Biological Data
### Philippe Boileau
### Graduate Group in Biostatistics <br> University of California, Berkeley <br> In Collaboration with Nima Hejazi and Sandrine Dudoit

---

class: middle, center, inverse

# Motivation



---
class: left, top

# Motivation

A common problem in the analysis of high-dimensional biological data is the
teasing out of biological signal from technical noise, i.e. the removal of
*unwanted* variation. 

.center[![:scale 60%](figures/batch_effect_example.png)]

???

This motivates the development of data-driven approaches for the "objective"
removal of unwanted variation in high-dimensional biological data. 
In particular, we are interested developing such a method for exploratory data
analysis.

---
class: middle, center, inverse

# Background

---
class: left, top

# cPCA

Given a **target** dataset containing both *wanted* and *unwanted* variation,
and a **background** dataset containing only *unwanted* variation, cPCA produces
a low-dimensional embedding of the target data reflecting (a portion of)
the variation not found in the background data.

.center[
![](figures/cPCA.png)

*Sketch of cPCA in action. (Figure 1 of Abid et al.)*
]

???


---
class: left, top

# Drawbacks

1. Like PCA in high dimensions, interpretting cPCA's loadings is difficult.
2. The contrastive parameter, `\(\alpha\)`, is selected visually.

.center[
![](figures/machine_learning.png)
]

???



---
class: left, top

# SPCA

SPCA provides interpretable loadings that are more stable in high dimensions.
How is this accomplished?

--

1. Re-frame PCA as a regression problem: PCA produces a linear manifold
approximation of the data.
2. Extend elasticnet regression to this regression problem. That is, include
`\(\ell_1\)` and `\(\ell_2\)` penalty terms to induce sparsity.

--

This second step isn't as staighforward as in the typical regression setting,
but it is possible to do it efficiently. [citation here]

---
class: middle, center, inverse

# Sparse Contrastive Principal Component Analysis (scPCA)

---
class: left, top

# scPCA

scPCA consists of applying SPCA on the contrastive covariance matrix of
target and background datasets. We get the best of both of cPCA and SPCA:

* Unwanted variation is removed from the target dataset
* scPCA's loadings are interpretable
* scPCA's loadings are stable

--

But what about the hyperparameters?

---
class: left, top

# Average Silhouette Width

Given `\(n\)` data points subjected to clustering, define `\(a(i)\)` and `\(b(i)\)` as
follows:
$$
`\begin{align}
  a(i) &amp; = \frac{1}{|C(i)|-1}\sum_{j\in C_i, i\neq j} d(i, j) \\
  b(i) &amp; = min_{k \neq i} \; \frac{1}{|C_k|}\sum_{j\in C_k} d(i, j)
\end{align}`
$$
That is, let `\(a(i)\)` be the mean distance between data point `\(i\)` and all other
data points in the same cluster, and let `\(b(i)\)` be the mean distance between
data point `\(i\)` and all data points in the nearest cluster.

The silhouette width is defined as
$$
s(i) = \frac{b(i) - a(i)}{max\\{a(i), b(i)\\}},
$$
and the average silhouette width is computed as
`\(\bar{s} = \frac{1}{n}\sum_{i=1}^n s(i)\)`.

???

The silhouette width and average silhouette width are bounded by -1 and 1.
Values close to 1 indicate that the data point(s) are well clustered.

---
class: left, top

# Hyperparameter Tuning

There are two main hyperparameters in the scPCA algorithm:
+ The constrastive parameter `\(\alpha\)`
+ The `\(\ell_1\)`-penalty parameter `\(\lambda_1\)` 

Hyperparameters are selected via a clustering-based grid-search method:

1. A grid of hyperparameters is specified
2. scPCA is performed for each pair of hyperparameters
3. A clustering algorithm is applied to the resulting low-dimensional embedding
4. Each embedding's quality is evaluated via the average silhouette width

The pair of hyperparameters that results in the largest average silhouette width
are identified as *optimal*.

A cross-validated variation also exists if finding non-generalizable patterns
in the data is a concern.

???
This attempts to solve one of the main issues with cPCA and SPCA, and can in
fact be generalized to both. However, it assumes that there are clusters in
the high-dimensional space.

---
class: left, top

# Implementation

The `scPCA` R package, released in Bioconductor 3.10, implements:
1. scPCA
2. cPCA with automated hyperparameter tuning
3. cross-validated scPCA and cPCA
4. cPCA with visual hyperparameter tuning

--

### Relevant details:

+ The hyperparameter tuning framework is embarrassingly parallel. Methods 1, 2, and 3 posses parallelized counterparts, making use of the `BiocParallel` infrastucture.
+ The `scPCA` package integrates fully with the `SingleCellExperiment` container class, allowing for these methods' seamless inclusion in scRNA-seq analysis pipelines. 
+ The scPCA method is applied to a contrastive covariance matrix; its running time is impacted by the number of features, not observations.

---
class: middle, center, inverse

# Example

---
class: left, top

# Simulated scRNA-seq Data

300 cells and 500 genes were simulated using the `Splat` framework, and
split into 3 equally sized groups.

.center[![:scale 60%](figures/full_sim_data.png)]

A number of leading dimensionality reduction methods were applied to the target
data to determine if they could disentangle the biological signal from the
batch effect.

???
Two groups had high levels of DE when compared to all others, making up the
target dataset, and the remaining group, which has low-levels of DE, makes up
the background data. A batch effect was included to mask the biological groups
in the target data.

---
class: left, top

# Simulated scRNA-seq Data (Cont.)

.center[![](figures/sim_results.png)]

---
class: left, top

# Simulated scRNA-seq Data (Cont.)

.center2[![:scale 200%](figures/sim_loadings.png)]

---
class: inverse, center, middle

# Fin.

---
class: left, top

# References
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="addons/macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
